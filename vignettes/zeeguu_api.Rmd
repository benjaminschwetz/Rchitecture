---
title: "zeeguu_api"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{zeeguu_api}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

### What is the system?

From the project website:

> Zeeguu-API is an open API that allows tracking and modeling the progress of a learner in a foreign language with the goal of recommending paths to accelerate vocabulary acquisition. The API is also currently deployed as the backend for the zeeguu.org website.

### What is the problem? 

I would like to find out what internal dependencies exist between modules in the project, i.e. produce a usage-dependency view. Furthermore, I produced some explorative visualizations to get a quick overview on how the repository is structured.


## Methodology

### tool support: 

I wrote my own scripts, with the following direct dependencies:

- [maligree/python-ast-explorer](https://github.com/maligree/python-ast-explorer) for parsing python AST into data structures. 
- ðŸ“¦`reticulate` for calling those python scripts from R
- ðŸ“¦`data.tree` for parsing yaml (and directories) into data.tree objects that could then be converted into igraph objects
- ðŸ“¦`igraph` behind the scenes and for implementations of different graph algorithms
- ðŸ“¦`tidygraph` for a tidy interface to manipulate the graphs
- ðŸ“¦`ggraph` for plotting graphs
- ðŸ“¦`dplyr` for data wrangling


```{r setup}
library(Rchitecture)
library(dplyr)
```


The code can be found on github: [benjaminschwetz/Rchitecture](https://github.com/benjaminschwetz/Rchitecture) ### data gathering: what sources of data did you use? Source viewpoints?

### Gathering data

I did a static analysis on the source code from the git repository:

```{r}
temp_folder <- tempdir()
zeeguu_path <- paste0(temp_folder, "/zeeguu_api")
git2r::clone(url = "https://github.com/zeeguu-ecosystem/Zeeguu-API.git",
             local_path  = zeeguu_path)
```

### Knowlegde Inference

I aimed to make this as automatic/tool driven as possible. The only knowledge inference I used was that I knew from lectures that it is a python project.


## Results

### Content table

This first table is more of a sanity check for the repository:

> Which file types occur most often and which files take most of the space?

```{r}
folder_contents <- content_table(zeeguu_path, include_folders = FALSE, temp_folder)
```

```{r}
folder_contents %>% 
  mutate(
    file_type = fct_infreq(file_type)
  ) %>% 
  group_by(file_type) %>% 
  summarise(
    n_files = n_distinct(file_name),
    file_size_sum = sum(size, na.rm = TRUE),
    file_size_median = median(size)
  ) %>% 
  mutate_if(is.numeric,round)
```
From this table we can see that: 
- it is likely a python project, because of the high number of python files
- using a sql database for storage, beause of the sql scripts
- It is a web applications, since it has a lot of html data.
- The project has a license
- It is using one docker image for the entire repo
- some shell scripts

### Repository structure view

While the table above gives some first indications, we loose most of the structural information through this aggregation. The following visualization aims to complement that. The path hierarchy of the repository is visualized in a circle-pack layout with fill color indicating the file type of the folder contents. First level subfolders are labelled for a better understanding.  
```{r}
visualize_folder_type_and_size(zeeguu_path, path_prefix = temp_folder)
```

This view shows that `Zeeguu_core` and `Zeeguu_api` are the two only pure python folders. `tools` contains the aformentioned sql scripts and most of the html is located in actually just located in the tests. 

### Package dependency view

I made a crude tokenizer from the `ast` module and used it to parse all `.py` files in the repository. Then I matched those tokens against the list of folder names in the repository to get a list of tokens that are (likely) dependencies. I then generated a graph, treating these mentions as edges. As it had too many nodes for a meaningful plot, I simplified the graph by aggregating the edges on a folder level. To preserve the weight information, I simply summed up the number of occurrences. I then arranged the nodes using a circular tree layout, based on the path hierarchy and encoded `occurences` in edge width and alpha. To make the plot more readable, I also scaled the nodes proportional to their centrality degree, counting incoming edges. 

```{r}
internal_dependency_graph(zeeguu_path, temp_folder)
```
The view cleary shows that `zeeguu_core` and more specifically `model` and `language` are heavily dependet on. One could argue that they were named properly. There is some overplotting occurring but it is still possible to look read dependencies for some of the nodes, i.e. `account_management` depends on the `teacher` module. 

## Discussion

### Limitations

The tokenizer is *very* crude, I am using the ast tree as is.  Unfortunately, from what I understand about python AST, this means relative paths and pythonian dot annotation ("class.method()") are not resolved as separate tokens. Furthermore, I create an edge if the token is equal to a folder name. This results in false positives if identical names occur several times in the folder hierarchy or some folders names happen to be identical to a string in the python script that is not an import. This limits the information content of the visualizations. Future work should thus focus on improving the tokenizer.


## Conclusion

The visualizations give a first impression of the project, answering the following questions:

- What type of files does the repository consist of?
- How are they distributed across subfolders (packages)?
- What are the main dependencies within the project?
